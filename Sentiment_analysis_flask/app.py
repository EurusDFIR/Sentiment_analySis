from flask import Flask, request, render_template, jsonify, session, redirect,url_for
import joblib
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import numpy as np
import os 

# --- Kh·ªüi t·∫°o ·ª©ng d·ª•ng Flask ---
app = Flask(__name__)

app.secret_key = os.urandom(24)
print("--- Kh·ªüi t·∫°o ·ª©ng d·ª•ng Flask ---") # Print 1

# --- L·∫•y ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c ---
basedir = os.path.abspath(os.path.dirname(__file__))
print(f"Th∆∞ m·ª•c c∆° s·ªü (basedir): {basedir}") # Print 2

# --- T·∫£i t√†i nguy√™n NLTK ---
print("--- B·∫Øt ƒë·∫ßu t·∫£i NLTK ---") # Print 3
print("NLTK data path:", nltk.data.path) # Print 4
try:
    stop_words = set(stopwords.words('english'))
    lemmatizer = WordNetLemmatizer()
    print("T·∫£i stopwords v√† lemmatizer th√†nh c√¥ng!") # Print 5
except LookupError as e:
    print(f"L·ªói LookupError khi t·∫£i NLTK: {e}") # Print 6 - L·ªói c·ª• th·ªÉ
    print("H√£y ch·∫°y l·∫°i nltk.download trong console.")
    stop_words = set()
    lemmatizer = None
except Exception as e:
    print(f"L·ªói kh√¥ng x√°c ƒë·ªãnh khi t·∫£i NLTK: {e}") # Print 7 - L·ªói kh√°c
    stop_words = set()
    lemmatizer = None


# --- H√†m ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n  ---
def preprocess_text(text):
    if lemmatizer is None:
        print("C·∫£nh b√°o: Lemmatizer ch∆∞a ƒë∆∞·ª£c t·∫£i.")
       
        return text # Tr·∫£ v·ªÅ text g·ªëc n·∫øu kh√¥ng c√≥ lemmatizer

    text = text.lower() # Chuy·ªÉn v·ªÅ ch·ªØ th∆∞·ªùng
    text = re.sub(r'<[^>]*>', '', text) # Lo·∫°i b·ªè HTML tags
    text = re.sub(r'[^a-zA-Z\s]', '', text) # Lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát
    tokens = text.split() # T√°ch t·ª´
    # Lemmatization v√† lo·∫°i b·ªè stopword
    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]
    return " ".join(tokens) # Gh√©p l·∫°i th√†nh chu·ªói


# --- T·∫£i m√¥ h√¨nh v√† vectorizer ƒë√£ l∆∞u ---
print("--- B·∫Øt ƒë·∫ßu t·∫£i Model v√† Vectorizer ---") # Print 8
model = None # Kh·ªüi t·∫°o l√† None
vectorizer = None # Kh·ªüi t·∫°o l√† None
model_path = os.path.join(basedir, 'sentiment_logreg_model.joblib')
vectorizer_path = os.path.join(basedir, 'tfidf_vectorizer.joblib')
print(f"ƒê∆∞·ªùng d·∫´n model d·ª± ki·∫øn: {model_path}") # Print 9
print(f"ƒê∆∞·ªùng d·∫´n vectorizer d·ª± ki·∫øn: {vectorizer_path}") # Print 10

try:
    print("ƒêang th·ª≠ t·∫£i model...") # Print 11
    model = joblib.load(model_path)
    print("T·∫£i model th√†nh c√¥ng!") # Print 12
    print("ƒêang th·ª≠ t·∫£i vectorizer...") # Print 13
    vectorizer = joblib.load(vectorizer_path)
    print("T·∫£i vectorizer th√†nh c√¥ng!") # Print 14
except FileNotFoundError:
    print(f"L·ªói FileNotFoundError: Kh√¥ng t√¨m th·∫•y file model ho·∫∑c vectorizer.") # Print 15
    print(f"ƒê√£ ki·ªÉm tra: {model_path} v√† {vectorizer_path}")
    # model v√† vectorizer v·∫´n l√† None
except Exception as e:
    print(f"L·ªói kh√¥ng x√°c ƒë·ªãnh khi t·∫£i model/vectorizer: {e}") # Print 16 - L·ªói kh√°c
    # model v√† vectorizer v·∫´n l√† None

print("--- Ho√†n t·∫•t t·∫£i t√†i nguy√™n ---") # Print 17
print(f"Tr·∫°ng th√°i model: {'ƒê√£ t·∫£i' if model is not None else 'Ch∆∞a t·∫£i (None)'}") # Print 18
print(f"Tr·∫°ng th√°i vectorizer: {'ƒê√£ t·∫£i' if vectorizer is not None else 'Ch∆∞a t·∫£i (None)'}") # Print 19
print(f"Tr·∫°ng th√°i lemmatizer: {'ƒê√£ t·∫£i' if lemmatizer is not None else 'Ch∆∞a t·∫£i (None)'}") # Print 20

# --- Route cho trang ch·ªß ---
@app.route('/')
def home():
    print("Truy c·∫≠p trang ch·ªß ('/')") # Print 21
    prediction_text = session.pop('prediction_text', None) # L·∫•y v√† x√≥a kh·ªèi session
    original_review = session.pop('original_review', None)
    is_error = session.pop('is_error', False)
    print("Truy c·∫≠p trang ch·ªß ('/')")
    return render_template('index.html',
                           prediction_text=prediction_text,
                           original_review=original_review,
                           error=is_error)

# --- Route x·ª≠ l√Ω d·ª± ƒëo√°n ---
@app.route('/predict', methods=['POST'])
def predict():
    print("Nh·∫≠n y√™u c·∫ßu d·ª± ƒëo√°n ('/predict') [POST]")
    if model is None or vectorizer is None or lemmatizer is None:
         print("L·ªói trong /predict: Model, Vectorizer ho·∫∑c Lemmatizer l√† None.")
         session['prediction_text'] = 'L·ªói: H·ªá th·ªëng ch∆∞a s·∫µn s√†ng ƒë·ªÉ d·ª± ƒëo√°n.'
         session['is_error'] = True
         return redirect(url_for('home'))

    if request.method == 'POST':
        review_text = request.form['review']
        print(f"Nh·∫≠n ƒë∆∞·ª£c ƒë√°nh gi√°: '{review_text[:50]}...'")

        if not review_text.strip():
             print("L·ªói trong /predict: ƒê√°nh gi√° r·ªóng.")
             session['prediction_text'] = 'Vui l√≤ng nh·∫≠p ƒë√°nh gi√° phim.'
             session['original_review'] = review_text # V·∫´n l∆∞u l·∫°i ƒë·ªÉ hi·ªÉn th·ªã
             session['is_error'] = True
             return redirect(url_for('home'))

        try:
            processed_text = preprocess_text(review_text)
            vectorized_text = vectorizer.transform([processed_text])
            prediction = model.predict(vectorized_text)
            sentiment = "T√≠ch c·ª±c üòä" if prediction[0] == 1 else "Ti√™u c·ª±c üòû"
            print(f"K·∫øt qu·∫£ d·ª± ƒëo√°n: {prediction[0]} ({sentiment})")

            # L∆∞u k·∫øt qu·∫£ v√† ƒë√°nh gi√° g·ªëc v√†o session
            session['prediction_text'] = f'D·ª± ƒëo√°n c·∫£m x√∫c: {sentiment}'
            session['original_review'] = review_text
            session['is_error'] = False # Kh√¥ng c√≥ l·ªói

        except Exception as e:
             print(f"L·ªói trong /predict khi x·ª≠ l√Ω/d·ª± ƒëo√°n: {e}")
             session['prediction_text'] = 'L·ªói trong qu√° tr√¨nh x·ª≠ l√Ω ho·∫∑c d·ª± ƒëo√°n.'
             session['original_review'] = review_text
             session['is_error'] = True

        # Lu√¥n chuy·ªÉn h∆∞·ªõng v·ªÅ trang ch·ªß sau khi x·ª≠ l√Ω POST
        return redirect(url_for('home'))

# --- Ch·∫°y ·ª©ng d·ª•ng ---
if __name__ == "__main__":
    pass
    print("app.py ƒë∆∞·ª£c ch·∫°y tr·ª±c ti·∫øp (kh√¥ng ph·∫£i qua WSGI)")